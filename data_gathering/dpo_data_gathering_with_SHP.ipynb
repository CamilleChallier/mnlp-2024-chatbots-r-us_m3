{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_dpo = load_dataset(\"json\", data_files=\"project-code-2024/datasets/M1_preference_data_15052024.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['course_id', 'question_complete', 'preference', 'question_id'],\n",
       "    num_rows: 1522\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_dpo[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A': '...',\n",
       "  'B': '...',\n",
       "  'criteria': {'clarity': 'None',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'B',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: B; Engagement: AB',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': 'To determine the asymptotic work of the `parGroupBy2` function, we first need to understand what this function does and how it operates.\\n\\nThe `parGroupBy2` function likely takes a collection of elements and groups them into pairs based on some criteria. The function name suggests that it may be parallelized, meaning that it may use multiple threads or processors to perform its operations in parallel.\\n\\nIn terms of determining the asymptotic work of this function, we need to consider the complexity of grouping the elements into pairs. If the function involves comparing every element to every other element to form pairs, the work complexity would likely be O(n^2), where n is the number of elements in the collection.\\n\\nHowever, if the function uses more efficient algorithms or data structures, such as hashing or sorting, the work complexity could be lower. For example, if the function sorts the elements first and then groups them into pairs in linear time, the work complexity could be O(n log n).\\n\\nIn conclusion, without more specific details about the implementation of the `parGroupBy2` function, it is difficult to determine its exact asymptotic work complexity. It will depend on the specific operations and algorithms used within the function.',\n",
       "  'B': \"When determining the asymptotic work of the `parGroupBy2` function, we need to consider the complexity of the algorithm used to group the elements into pairs. Let's break down the steps of my previous answer carefully:\\n\\n1. Understanding the function:\\n   - The `parGroupBy2` function likely takes a collection of elements and groups them into pairs based on some criteria. The function name suggests that it may be parallelized, meaning it may perform its operations using multiple threads or processors.\\n\\n2. Consider the grouping process:\\n   - If the function involves comparing every element to every other element to form pairs, the work complexity would likely be O(n^2), where n is the number of elements in the collection. This is because for each element in the collection, we may need to compare it with every other element to form pairs.\\n\\n3. Efficiency of algorithms or data structures:\\n   - If the function uses more efficient algorithms or data structures, such as hashing or sorting, the work complexity could be lower. For example, if the function sorts the elements first and then groups them into pairs in linear time, the work complexity could be O(n log n).\\n\\n4. Conclusion:\\n   - Without specific details about the implementation of the `parGroupBy2` function, it is challenging to determine its exact asymptotic work complexity. The complexity will depend on the specific operations and algorithms used within the function.\\n\\nBy carefully considering the steps outlined above, we can better understand how the asymptotic work complexity of the `parGroupBy2` function can be determined based on the grouping process and the efficiency of the algorithms or data structures used.\",\n",
       "  'criteria': {'clarity': 'B',\n",
       "   'completeness': 'B',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'B'},\n",
       " {'A': 'The asymptotic work of GroupBy is O(n), where n is the number of items in the collection being grouped. This is because GroupBy iterates through the collection once to create the groups, so the time complexity is linear with respect to the number of items in the collection.',\n",
       "  'B': 'The asymptotic work of `GroupBy` is O(n), where n is the number of elements in the input collection. \\\\n\\\\nThis is because the `GroupBy` operation involves iterating through each element of the input collection once, and then placing each element into a group based on a specified key or criteria. This process has a linear time complexity, as it requires examining each element exactly once to determine its group.\\\\n\\\\nTherefore, the overall time complexity of `GroupBy` is O(n), making it a relatively efficient operation for grouping elements in a collection.',\n",
       "  'criteria': {'clarity': 'AB',\n",
       "   'completeness': 'B',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'B'},\n",
       " {'A': \"To determine the asymptotic work of `parGroupBy2`, we can break it down into its individual steps and analyze the work complexity of each step:\\n\\n1. The initial grouping of elements based on the provided key function: This step involves iterating through all elements in the input list and grouping them based on the key function. The work complexity of this step is O(n), where n is the number of elements in the input list.\\n\\n2. Applying the provided function to each group in parallel: Once the elements are grouped, the provided function is applied to each group in parallel. The work complexity of this step depends on the complexity of the provided function and the number of groups. Let's denote the number of groups as k.\\n\\n3. Combining the results of the parallel computations: After the parallel computations are complete, the results need to be combined into a final result. The work complexity of this step is O(k), where k is the number of groups.\\n\\nOverall, the asymptotic work complexity of `parGroupBy2` can be expressed as O(n + k), where n is the number of elements in the input list and k is the number of groups created during the initial grouping step.\\n\\nIt's important to note that the actual work complexity may vary depending on the specific implementation details and the parallel processing framework being used.\",\n",
       "  'B': 'To determine the asymptotic work of `parGroupBy2`, we need to analyze the steps involved in the algorithm.\\n\\n1. The initial step is to split the input list into two equal parts. This step has a work complexity of O(n), where n is the number of elements in the input list.\\n\\n2. The next step is to perform the grouping operation on each of the two parts in parallel. This involves creating a dictionary to store the grouped elements. Each element in the input list needs to be inserted into the dictionary, which has an average work complexity of O(1) for each insertion.\\n\\n3. Finally, the two dictionaries created in parallel need to be merged into a single dictionary. This merge operation involves iterating over one of the dictionaries and inserting its elements into the other dictionary. The complexity of this merge operation is O(m), where m is the number of elements in the smaller dictionary.\\n\\nOverall, the work complexity of the `parGroupBy2` algorithm can be approximated as O(n) + O(n) + O(m) = O(n + m).\\n\\nTherefore, the asymptotic work complexity of `parGroupBy2` is O(n + m), where n is the number of elements in the input list and m is the number of unique keys in the grouped output.',\n",
       "  'criteria': {'clarity': 'AB',\n",
       "   'completeness': 'AB',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': \"The asymptotic work of `parGroupBy2` signifies the computational complexity associated with its parallel processing efficiency concerning increasing input size. In an optimized scenario where tasks are evenly distributed among threads and synchronization overhead is minimized, the asymptotic work is O(log n). This logarithmic scalability reflects the algorithm's effective handling of larger datasets through parallel data grouping and aggregation, showcasing notable efficiency and resource utilization benefits in parallel computing environments.\",\n",
       "  'B': 'The asymptotic work of `parGroupBy2` is O(log n) when considering a well-optimized parallel execution environment with efficient workload distribution and synchronization mechanisms in place.',\n",
       "  'criteria': {'clarity': 'AB',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': \"Answer: The parGroupBy2 function groups elements in the input list into pairs, where each pair consists of two consecutive elements from the list. Since each pair consists of two elements, the total number of pairs will be half of the number of elements in the input list. \\n\\nLet's denote the number of elements in the list as n. In the worst-case scenario, we will form n/2 pairs. This results in a time complexity of O(n/2) for the parGroupBy2 function. However, in Big O notation, we drop constants and coefficients, so the correct asymptotic work of the parGroupBy2 function is O(n), where n is the number of elements in the input list.\\n\\nTherefore, the correct asymptotic work of parGroupBy2 is O(n), where n is the number of elements in the input list.\",\n",
       "  'B': \"Firstly, let's understand what the function <code>parGroupBy2</code> does. This function partitions a list into groups of 2 elements each.\\n\\nTo calculate the asymptotic work of this function, we need to consider the time complexity of each operation involved.\\n\\n1. Partitioning the list into groups of 2 elements each: This operation requires iterating over the entire list and creating pairs of elements. The time complexity of this operation is O(n/2) = O(n), where n is the number of elements in the list.\\n\\n2. Grouping the pairs into separate lists: This operation also requires iterating over the list of pairs and creating separate lists for each pair. The time complexity of this operation is also O(n/2) = O(n).\\n\\nTherefore, the total asymptotic work of the <code>parGroupBy2</code> function can be expressed as O(n) + O(n) = O(2n) = O(n).\\n\\nSo, the asymptotic work of <code>parGroupBy2</code> is O(n).\",\n",
       "  'criteria': {'clarity': 'B',\n",
       "   'completeness': 'B',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'B'},\n",
       " {'A': 'The asymptotic work of <code>parGroupBy2</code> is O(n), where n is the number of elements in the input list. This function splits the input list into groups of two elements each and processes each group independently in parallel. By leveraging parallel processing, the function achieves a linear time complexity, making it efficient for large input sizes.',\n",
       "  'B': \"The asymptotic work of <code>parGroupBy2</code> is O(n log n), where n represents the size of the input list. The function's approach to grouping elements involves some recursive steps that introduce a logarithmic factor to the overall time complexity. However, the exact complexity can vary depending on the specific implementation details and optimizations applied.\",\n",
       "  'criteria': {'clarity': 'A',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'A',\n",
       "   'modified': None,\n",
       "   'other': 'None',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': \"1. First, we need to understand what the function `parGroupBy2` does. This function takes a list of elements and groups them into pairs of two. If the number of elements in the list is odd, the last element is left out.\\n\\n2. To determine the asymptotic work of `parGroupBy2`, we need to consider the number of operations required as the input size grows.\\n\\n3. Let's denote the input size as `n`, where `n` is the number of elements in the list.\\n\\n4. The function `parGroupBy2` will first need to iterate through the list to group the elements into pairs. This requires iterating through `n/2` pairs.\\n\\n5. Therefore, the asymptotic work of `parGroupBy2` can be expressed as O(n) since the function needs to iterate through each element in the list once.\\n\\n6. In conclusion, the asymptotic work of `parGroupBy2` is O(n), where `n` is the number of elements in the input list.\",\n",
       "  'B': \"let's define <code>parGroupBy2</code> as a function that takes a list of elements and groups them into pairs (tuples of size 2) using parallel processing. \\n\\nThe asymptotic work of <code>parGroupBy2</code> can be analyzed as follows:\\n1. Split the list into pairs of elements in parallel: This step involves dividing the list into pairs of elements, which can be done in parallel. The work for this step is O(n), where n is the number of elements in the list.\\n2. Group the pairs into a single list: Once the pairs are created, they need to be grouped into a single list. This step also has a work complexity of O(n) as each pair needs to be added to the final list.\\n\\nTherefore, the total asymptotic work of <code>parGroupBy2</code> is O(n), where n is the number of elements in the input list. The parallel processing helps in reducing the overall time complexity of the operation.\",\n",
       "  'criteria': {'clarity': 'AB',\n",
       "   'completeness': 'B',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'B'},\n",
       "  'overall': 'B'},\n",
       " {'A': 'The asymptotic work of the function `parGroupBy2` can be analyzed by looking at its time complexity. In this case, the function is grouping elements in a list by pairs. \\n\\nTo group elements in pairs, the function needs to iterate through the list and create pairs of adjacent elements. This requires visiting each element of the list once. Therefore, the time complexity of creating pairs in the list is O(n), where n is the number of elements in the list.\\n\\nHence, the asymptotic work of the `parGroupBy2` function is O(n), where n is the number of elements in the list.',\n",
       "  'B': \"The asymptotic work of `parGroupBy2` can be determined by analyzing its algorithmic complexity. \\n\\nIf `parGroupBy2` is a function that performs a parallel grouping operation on a collection of elements, let's assume it has a time complexity of O(n) where n is the number of elements in the collection. \\n\\nIn a parallel algorithm, the work is often determined by the maximum number of operations that need to be performed in parallel at any given time. In this case, since `parGroupBy2` is a parallel operation, the maximum number of operations that can be performed in parallel is limited by the number of available processing units or threads.\\n\\nTherefore, the asymptotic work of `parGroupBy2` can be approximated as O(n/p), where p is the number of available processing units or threads. This indicates that the work done by the algorithm decreases as the number of processing units increases, making it more efficient in a parallel computing environment.\\n\\nIt's important to note that the actual performance of the algorithm may vary depending on the specific implementation, the characteristics of the input data, and the hardware on which it is run.\",\n",
       "  'criteria': {'clarity': 'None',\n",
       "   'completeness': 'AB',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': 'comprehensiveness: A; scalability: A',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': '##Answer:\\nThe asymptotic work of `parGroupBy2` is $O(n)$.\\n\\n##Reasons:\\n1. **Work Complexity:** In parallel computing, the term \"work\" refers to the total amount of computation performed by an algorithm, ignoring any parallelism or resource constraints. It represents the total number of operations required to complete the task.\\n2. **Understanding `parGroupBy2`:** The function `parGroupBy2` likely involves splitting a data structure into two parts and processing each part independently before combining the results.\\n3. **Linear Complexity:** The asymptotic work of `parGroupBy2` is $O(n)$, where $n$ represents the size of the input data structure. This complexity arises from the fact that the function processes each element of the input in a single pass, leading to a linear relationship between the input size and the total work performed.\\n4. **Parallel Efficiency:** While the function may involve parallel processing or splitting the input into two parts, the overall work complexity remains linear because the total amount of computation scales directly with the input size.\\n5. **Scalability:** A linear work complexity indicates that the function\\'s computational requirements grow proportionally with the input size, making it efficient for handling larger datasets without exponential increases in computation.\\n6. **Rationale:** The work complexity of `parGroupBy2` being $O(n)$ implies that the function\\'s overall computational effort is directly proportional to the size of the input, allowing for predictable and scalable performance characteristics.\\n\\nIn summary, the asymptotic work of `parGroupBy2` is $O(n)$, signifying a linear relationship between the input size and the total computational effort required to process the data in a parallel grouping context.',\n",
       "  'B': '##Answer:\\nThe asymptotic work of `parGroupBy2` is $O(n)$.\\n\\n##Reasons:\\n1. The `parGroupBy2` operation involves grouping elements of a parallel collection into buckets based on a grouping function.\\n2. The work complexity of `parGroupBy2` is determined by the total number of elements in the collection, denoted as $n$.\\n3. When grouping the elements, each element needs to be processed to determine its group, resulting in a linear amount of work proportional to the number of elements in the collection.\\n4. As a result, the asymptotic work complexity of `parGroupBy2` is $O(n)$, indicating that the amount of work required grows linearly with the size of the input collection.',\n",
       "  'criteria': {'clarity': 'AB',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': 'To determine the asymptotic work of `parGroupBy2`, we need to consider the work done at each step of the algorithm. \\n\\n1. The initial step involves splitting the input list into two sublists. This step has a work complexity of O(n) as it involves iterating through the input list once.\\n\\n2. The next step involves grouping the elements of each sublist by a key using a parallel strategy. This step has a work complexity of O(n) as it involves iterating through each sublist once.\\n\\n3. Finally, the results from both sublists are combined into a single result. This step has a work complexity of O(n) as it involves combining the results from both sublists.\\n\\nOverall, the total work complexity of `parGroupBy2` is O(n) + O(n) + O(n) = O(n). \\n\\nTherefore, the asymptotic work of `parGroupBy2` is O(n).',\n",
       "  'B': 'The correct answer to the question would depend on the specific implementation of the function <code>parGroupBy2</code>. \\n\\nIf <code>parGroupBy2</code> is a function that parallelizes the grouping of elements in a list by dividing the list into two equal parts and then recursively grouping each part, the asymptotic work would be O(n). This is because at each level of recursion, the function processes half of the elements in the list, and the total number of operations scales linearly with the size of the input list.\\n\\nIf <code>parGroupBy2</code> utilizes a different approach or algorithm, the asymptotic work could be different. It would be important to understand the specific implementation of the function in order to accurately determine the asymptotic work.',\n",
       "  'criteria': {'clarity': 'B',\n",
       "   'completeness': 'None',\n",
       "   'correctness': 'B',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: B; Engagement: B',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'B'},\n",
       " {'A': 'To determine the asymptotic work of `parGroupBy2`, we need to analyze the steps involved in the function.\\n\\n1. The function takes an input list of elements.\\n2. It creates a dictionary to store the groups of elements based on a grouping function.\\n3. It then iterates through each element in the input list and assigns it to the corresponding group in the dictionary.\\n4. Finally, it returns the dictionary containing the grouped elements.\\n\\nThe main operation in this function is iterating through each element in the input list, which has a time complexity of O(n), where n is the number of elements in the input list.\\n\\nTherefore, the asymptotic work of `parGroupBy2` is O(n), where n is the number of elements in the input list.',\n",
       "  'B': 'The asymptotic work of the `parGroupBy2` function is O(n), where n is the number of elements in the input list. This is because the function splits the input list into two groups in parallel, which requires O(n) work to process each element in the list.',\n",
       "  'criteria': {'clarity': 'A',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: A; Engagement: B',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'A'},\n",
       "  'overall': 'A'},\n",
       " {'A': \"To determine the asymptotic work of `parGroupBy2`, we need to consider the work and span of the algorithm. \\n\\nThe `parGroupBy2` function is typically used to group elements of a list based on some criteria. The algorithm divides the list into two sublists, applies the grouping operation independently on each sublist, and then merges the results. \\n\\nLet's break down the work and span of `parGroupBy2`:\\n\\n1. Work:\\n   - Dividing the list into two sublists: O(n)\\n   - Applying the grouping operation on each sublist independently: O(n) for each sublist\\n   - Merging the results: O(n)\\n   - Total work = O(n) + O(n) + O(n) = O(n)\\n\\n2. Span:\\n   - Dividing the list into two sublists: O(1)\\n   - Applying the grouping operation on each sublist independently: O(n) for each sublist\\n   - Merging the results: O(1)\\n   - Total span = O(1) + O(n) + O(1) = O(n)\\n\\nTherefore, the asymptotic work and span of `parGroupBy2` are both O(n). This means that the algorithm scales linearly with the size of the input list.\\n\\nYou should trust this analysis because it is based on the fundamental principles of algorithm analysis, specifically considering the work and span of the algorithm. The breakdown provided gives a clear explanation of how the algorithm operates and how its complexity grows with the input size. Additionally, the analysis is simple and concise, making it easy to understand and trust.\",\n",
       "  'B': \"To determine the asymptotic work of `parGroupBy2`, we first need to consider the steps involved in the function and then analyze the complexity of each step.\\n\\nHere is a development of the function `parGroupBy2`:\\n1. The function takes a list of elements and a grouping function as input.\\n2. It applies the grouping function to each element in the list to determine the key for grouping.\\n3. It then groups the elements based on the keys generated by the grouping function.\\n4. The grouping operation involves iterating over the list of elements to determine the key and then adding the element to the corresponding group.\\n\\nNow, let's break down the complexity of each step:\\n- Applying the grouping function to each element: This step has a time complexity of O(n), where n is the number of elements in the list.\\n- Grouping the elements based on the keys: This step also has a time complexity of O(n), as it involves iterating over the list once to assign elements to groups.\\n\\nTherefore, the overall time complexity of `parGroupBy2` is O(n), where n is the number of elements in the input list.\\n\\nExample:\\n```javascript\\nconst list = [1, 2, 3, 4, 5];\\nconst groupingFunction = (element) => element % 2 === 0 ? 'even' : 'odd';\\n\\nconst grouped = parGroupBy2(list, groupingFunction);\\nconsole.log(grouped);\\n// Output: { odd: [1, 3, 5], even: [2, 4] }\\n```\\n\\nIn this example, the `parGroupBy2` function takes a list of numbers and groups them into two groups based on whether the number is even or odd. The time complexity of this operation is O(n), where n is the number of elements in the input list.\",\n",
       "  'criteria': {'clarity': 'A',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: B; Engagement: AB',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': '4. Ontologies dictate how semi-structured data are serialized\\n\\nThis statement is wrong regarding Ontologies. Ontologies do not dictate how semi-structured data are serialized. Instead, they provide a structured framework for defining concepts and relationships within a specific domain. Serialization of data is typically a separate process that may involve mapping data to the ontology structure but is not directly dictated by the ontology itself.',\n",
       "  'B': '4. Ontologies dictate how semi-structured data are serialized\\n\\nThis statement is wrong regarding Ontologies. Ontologies do not dictate how semi-structured data are serialized. Ontologies are primarily used for creating a formal representation of knowledge within a specific domain. They define the concepts and relationships within that domain, helping to standardize terminology and provide a common understanding of the domain.\\n\\nOntologies can be used to integrate data expressed in different models by providing a common framework for understanding and organizing information. They also support domain-specific vocabularies, allowing for more precise and consistent communication within a particular field.\\n\\nAdditionally, it is possible to create more than one ontology that conceptualizes the same real-world entities. Different ontologies may have varying levels of granularity, focus on different aspects of the domain, or be used for different purposes. This flexibility allows for ontologies to be tailored to specific needs and contexts.',\n",
       "  'criteria': {'clarity': 'B',\n",
       "   'completeness': 'B',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': '',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'B'},\n",
       " {'A': 'As a doctoral student, I would approach this question using chain of thought reasoning to analyze the asymptotic work of the function `parGroupBy2`.\\n\\nFirst, I would consider the definition of `parGroupBy2` and break down its algorithmic steps. This function likely involves grouping elements in a collection based on a certain criterion, and performing this grouping operation in parallel to improve efficiency.\\n\\nNext, I would analyze the complexity of the parallel grouping operation in terms of time and work. The asymptotic work of a parallel algorithm is generally influenced by factors such as the number of elements in the input collection, the number of processors available for parallel processing, and the efficiency of the parallelization strategy used.\\n\\nI would also consider any potential overhead associated with parallel processing, such as communication costs between processors or synchronization overhead. These factors can impact the overall work complexity of the algorithm.\\n\\nIn conclusion, the asymptotic work of `parGroupBy2` would depend on the specific implementation details of the parallel grouping algorithm, as well as the input size and available resources. Further analysis and experimentation would be needed to determine the exact complexity of this function.',\n",
       "  'B': 'As a university professor, I would employ chain of thought reasoning to approach the question of the asymptotic work of the function `parGroupBy2`.\\n\\nFirstly, I would consider the underlying algorithmic approach used in the `parGroupBy2` function. This function likely involves some form of parallel processing to group elements in a collection based on a specified criterion.\\n\\nNext, I would analyze the computational complexity of the parallel grouping operation. The asymptotic work of a parallel algorithm is influenced by factors such as the size of the input data, the number of processors available for parallelization, and the overhead associated with parallel processing.\\n\\nI would also take into account any potential inefficiencies or bottlenecks in the parallelization strategy used in the `parGroupBy2` function. Factors such as communication overhead, synchronization costs, and load balancing can impact the overall work complexity of the algorithm.\\n\\nAdditionally, I would consider the scalability of the `parGroupBy2` function in terms of input size and the number of available processors. Understanding how the algorithm performs as the input data grows larger or as more processors are utilized is crucial in determining the asymptotic work complexity.\\n\\nIn conclusion, the asymptotic work of the `parGroupBy2` function would depend on a combination of factors such as the algorithmic design, input size, parallelization strategy, and resource availability. Further analysis and experimentation would be necessary to determine the exact asymptotic work complexity of this function.',\n",
       "  'criteria': {'clarity': 'B',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'A',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: A, Engagement: A',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'A'},\n",
       "  'overall': 'A'},\n",
       " {'A': \"To determine the asymptotic work of the <code>parGroupBy2</code> function, we first need to understand what the function does and how it operates. The <code>parGroupBy2</code> function is a parallel algorithm that groups elements of a list into sublists based on a specified key function. It then combines the sublists into a single list in parallel, utilizing multiple processors or cores to speed up the process.\\n\\nThe asymptotic work of an algorithm refers to the amount of work done by the algorithm as the input size approaches infinity. It is often denoted by the Big-O notation, which provides an upper bound on the growth rate of the algorithm's running time.\\n\\nIn the case of the <code>parGroupBy2</code> function, the algorithm involves two main steps: the grouping of elements into sublists based on a key function and the combining of these sublists into a single list. \\n\\nThe grouping step requires iterating through each element in the input list and assigning it to the appropriate sublist based on the key function. This step has a time complexity of O(n), where n is the number of elements in the input list.\\n\\nThe combining step involves merging the sublists into a single list. This step also has a time complexity of O(n), where n is the total number of elements across all sublists.\\n\\nSince both steps involve linear time complexity, the overall time complexity of the <code>parGroupBy2</code> function is O(n), where n is the number of elements in the input list.\\n\\nTherefore, the asymptotic work of the <code>parGroupBy2</code> function is O(n). This means that the amount of work done by the function grows linearly with the size of the input list, making it an efficient algorithm for grouping and combining elements in parallel. \\n\\n{'Answer': 'O(n)'}\",\n",
       "  'B': 'The asymptotic work of `parGroupBy2` is O(n), where n is the number of elements in the input list. This is because the function first divides the input list into groups of 2 elements, which can be done in linear time. Then, it applies the `groupByKey` operation to each group, which also has a linear time complexity. Therefore, the overall time complexity of `parGroupBy2` is O(n).',\n",
       "  'criteria': {'clarity': 'A',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: A; Engagement: A',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'A'},\n",
       "  'overall': 'A'},\n",
       " {'A': 'In computer systems, understanding the concept of asymptotic work is essential when analyzing algorithms. Asymptotic work refers to the total amount of work done by an algorithm as the input size grows to infinity. It helps in understanding the efficiency of an algorithm in terms of the number of basic operations it performs.\\n\\nThe function <code>parGroupBy2</code> likely refers to a parallel algorithm that groups elements of an input list into pairs. In parallel algorithms, work is usually distributed across multiple processing units to exploit concurrency and improve performance.\\n\\nTo determine the asymptotic work of <code>parGroupBy2</code>, we need to consider how the grouping operation is carried out and how the work is distributed among parallel units. If the grouping operation can be done in constant time for each pair of elements, and if the parallel units can work independently without significant overhead, then the asymptotic work may be O(n), where n is the size of the input list.\\n\\nHowever, if the grouping operation involves more complex computations or if coordination among parallel units is required, the asymptotic work may be higher. In such cases, the asymptotic work could be O(n log n) or even higher, depending on the specific implementation details.\\n\\nTo provide a precise answer to the question about the asymptotic work of <code>parGroupBy2</code>, we would need more information about the implementation of the algorithm, the nature of the grouping operation, and how parallelism is utilized. Without this detailed information, it is challenging to give a definitive answer.',\n",
       "  'B': 'To determine the asymptotic work of `parGroupBy2`, we first need to understand what the function does and how it operates.\\n\\nThe function `parGroupBy2` seems to be a parallel version of the `groupBy` operation. The `groupBy` operation typically groups elements of a collection based on a given key function. In this case, `parGroupBy2` seems to parallelize this grouping process.\\n\\nTo calculate the asymptotic work of `parGroupBy2`, we need to consider the work done at each step of the operation. In a parallel operation, the work is typically calculated by considering the work done by each processor in parallel.\\n\\n1. **Partitioning**: The input data needs to be partitioned among the processors. This step involves dividing the input data into chunks that will be processed in parallel. The work done in this step is typically O(n), where n is the size of the input data.\\n\\n2. **Grouping**: Each processor will operate on its partition of the data and group the elements based on the key function. The work done in this step is also O(n), where n is the size of the input data.\\n\\n3. **Combining results**: Once all processors have completed their grouping operation, the results need to be combined to form the final output. The work done in this step is typically O(n), where n is the size of the input data.\\n\\nOverall, the asymptotic work of `parGroupBy2` can be approximated as O(n), where n is the size of the input data. This is because each step of the operation involves O(n) work, and in parallel operations, the work is typically bounded by the work done in the most time-consuming step.\\n\\nIn conclusion, the asymptotic work of `parGroupBy2` is O(n), where n is the size of the input data.',\n",
       "  'criteria': {'clarity': 'AB',\n",
       "   'completeness': 'B',\n",
       "   'correctness': 'A',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: A; Engagement: B',\n",
       "   'overall': 'A',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'A'},\n",
       " {'A': 'The asymptotic work of the `parGroupBy2` function depends on how it is implemented and the complexity of the operations it performs. The function `parGroupBy2` suggests that it might be using parallel processing to group elements in a collection. \\n\\nIf we assume that the parallel processing implementation divides the work evenly among available processors and has a complexity of O(n) for each group operation, where n is the number of elements in the collection, then the overall asymptotic work would be O(n).\\n\\nHowever, without more specific details about the implementation of `parGroupBy2` and the underlying operations it performs, it is difficult to provide a more precise analysis of its asymptotic work complexity.',\n",
       "  'B': \"The asymptotic work of the `parGroupBy2` function can be determined by analyzing its computational complexity. In this case, the function operates by grouping elements of a list into sublists of size 2. \\n\\nLet's assume the input list has a size of `n`, then the function will create `n/2` sublists of size 2. The work involved in creating these sublists is `O(n)` as we iterate through each element of the input list once to group them into pairs.\\n\\nTherefore, the asymptotic work of the `parGroupBy2` function is `O(n)`.\",\n",
       "  'criteria': {'clarity': 'B',\n",
       "   'completeness': 'A',\n",
       "   'correctness': 'AB',\n",
       "   'modified': None,\n",
       "   'other': 'Conciseness: AB; Engagement: AB',\n",
       "   'overall': 'B',\n",
       "   'relevance': 'AB'},\n",
       "  'overall': 'B'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_dpo[\"train\"][\"preference\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(p) for p in m1_dpo[\"train\"][\"preference\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length_by_words(pair, min_words = 30, max_words = 200):\n",
    "    return (min_words <= len(pair['A'].split()) <= max_words) and (min_words <= len(pair['B'].split()) <= max_words)\n",
    "\n",
    "def check_length_by_characters(pair, min_length = 200, max_length = 700):\n",
    "    return (min_length <= len(pair['A'].split()) <= max_length) and (min_length <= len(pair['B'].split()) <= max_length)\n",
    "\n",
    "def filter_by_length(sample:dict, check=check_length_by_characters):\n",
    "    for pair in sample[\"preference\"]:\n",
    "        # print(len(pair['A']))\n",
    "        # print(len(pair['B']))\n",
    "        if check(pair):\n",
    "            return True\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db9a06d369449d49306c77b416ae276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['course_id', 'question_complete', 'preference', 'question_id'],\n",
       "    num_rows: 1202\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_dpo[\"train\"].filter(filter_by_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1007a1cd42044fd90aa4775fb338686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329426d8590d4e1499e1cbbad10b058b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "def choose_preference_pair_id(prefenrences:list[dict], method:Literal[\"random\", \"length_in_characters\"]=\"length_in_characters\"):\n",
    "    if method==\"random\":\n",
    "        preference_pair_id = random.randint(0, len(prefenrences)-1)\n",
    "    elif method == \"length_in_characters\":\n",
    "        # choose_from_idxs = []\n",
    "        # for i, pair in enumerate(prefenrences):\n",
    "        #     print(f\"{pair=}\")\n",
    "        #     if ((len(pair['A']) > min_length) and (len(pair['B']) > min_length)):\n",
    "        #         choose_from_idxs += [i]\n",
    "        choose_from_idxs = [i for i, pair in enumerate(prefenrences) if check_length_by_characters(pair)]\n",
    "        # print(choose_from_idxs)\n",
    "        preference_pair_id = random.choice(choose_from_idxs)\n",
    "    return preference_pair_id\n",
    "\n",
    "\n",
    "def choose_random_preference_pair(sample:dict)->dict:\n",
    "    preference_pair_id = choose_preference_pair_id(sample[\"preference\"])\n",
    "    chosen_key = sample[\"preference\"][preference_pair_id]['criteria']['overall']\n",
    "    other_mapping = {\n",
    "        'A':'B',\n",
    "        'B':'A'\n",
    "    }\n",
    "    rejected_key = other_mapping[chosen_key]\n",
    "    sample[\"chosen\"] = sample[\"preference\"][preference_pair_id][chosen_key]\n",
    "    sample[\"rejected\"] = sample[\"preference\"][preference_pair_id][rejected_key]\n",
    "    sample[\"prompt\"] = sample[\"question_complete\"]\n",
    "    for useless_key in ['preference', 'course_id', 'question_complete', 'question_id']:\n",
    "        sample.pop(useless_key)\n",
    "    # sample = {k:v for k, v in sample.items() if k in [\"chosen\", \"rejected\", \"prompt\"]}\n",
    "    return sample\n",
    "\n",
    "random.seed(42)\n",
    "m1_dpo[\"train\"] = m1_dpo[\"train\"].filter(filter_by_length)\n",
    "m1_dpo[\"train\"] = m1_dpo[\"train\"].map(choose_random_preference_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected', 'prompt'],\n",
       "    num_rows: 1202\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_dpo[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_dpo = m1_dpo[\"train\"].train_test_split(0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d70420b7a8477282b5fcc200c0276e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246762006bcd4a9297c9220d643a34e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in m1_dpo.keys():\n",
    "    m1_dpo[split].to_json(os.path.join(\"project-code-2024\", \"datasets\", f\"dpo_M1_15052024_length_200-700_{split}.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI WebGPT Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 127M/127M [01:02<00:00, 2.03MB/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e313d72b2e48c89ba933615f2c74d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/19578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "webgpt_dataset = load_dataset(\"openai/webgpt_comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'quotes_0', 'answer_0', 'tokens_0', 'score_0', 'quotes_1', 'answer_1', 'tokens_1', 'score_1'],\n",
      "        num_rows: 19578\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(webgpt_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_same_responses = lambda example: example['score_0'] != 0 and example['score_1'] != 0\n",
    "\n",
    "def process_webgpt(example:dict):\n",
    "    example['chosen'] = example['answer_0'] if example['score_0'] > example['score_1'] else example['answer_1']\n",
    "    example['rejected'] = example['answer_1'] if example['score_0'] > example['score_1'] else example['answer_0']\n",
    "    example['prompt'] = example['question']['full_text']\n",
    "    for useless_key in ['question', 'quotes_0', 'answer_0', 'tokens_0', 'score_0', 'quotes_1', 'answer_1', 'tokens_1', 'score_1']:\n",
    "        example.pop(useless_key)\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5709a3537b444fb781f1443293b25740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/19578 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "webgpt_dataset[\"train\"] = webgpt_dataset[\"train\"].filter(filter_same_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4459e4b47ecb44a6b9b4993097b57b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14346 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "webgpt_dataset[\"train\"] = webgpt_dataset[\"train\"].map(process_webgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c828d34a943f4e0e9b2970b11392e25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "25091329"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webgpt_dataset[\"train\"].to_json(os.path.join(\"project-code-2024\", \"datasets\", f\"dpo_webgpt_comparaisons.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orca = load_dataset(\"Intel/orca_dpo_pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['system', 'question', 'chosen', 'rejected'],\n",
       "        num_rows: 12859\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042c3084b0a143f1a20de7d138f274b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12859 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_orca_sample(sample:dict)->dict:\n",
    "    sample[\"prompt\"] = sample[\"question\"]\n",
    "    for useless_key in ['question', 'system']:\n",
    "        sample.pop(useless_key)\n",
    "    return sample\n",
    "\n",
    "orca['train'] = orca['train'].map(process_orca_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['chosen', 'rejected', 'prompt'],\n",
       "        num_rows: 12859\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39cb4932d1c4cb687b725835717a0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "34429694"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca[\"train\"].to_json(os.path.join(\"project-code-2024\", \"datasets\", f\"dpo_orca_train.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stanford Human Preferences Dataset (SHP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_dataset_full = load_dataset(\"stanfordnlp/SHP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shp_dataset_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_train_full = shp_dataset_full['train']\n",
    "print(shp_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_train = shp_train_full.filter(lambda example: example['domain'] in ['askacademia'])\n",
    "print(shp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only take the 4 domains:\n",
    "# askacademia, askengineers, askphysics, askscience\n",
    "shp_dataset_train = shp_dataset_full.filter(lambda example: example['domain'] in ['askacademia_train', 'askengineers_train', 'askphysics_train', 'askscience_train'])\n",
    "shp_dataset_train = shp_dataset_train['train']\n",
    "print(shp_dataset_train)\n",
    "\n",
    "shp_dataset_eval = shp_dataset_full.filter(lambda example: example['domain'] in ['askacademia_validation', 'askengineers_validation', 'askphysics_validation', 'askscience_validation'])\n",
    "shp_dataset_eval = shp_dataset_eval['validation']\n",
    "print(shp_dataset_eval)\n",
    "\n",
    "shp_dataset_test = shp_dataset_full.filter(lambda example: example['domain'] in ['askacademia_test', 'askengineers_test', 'askphysics_test', 'askscience_test'])\n",
    "shp_dataset_test = shp_dataset_test['test']\n",
    "print(shp_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels -> 1 if A is preferred to B, 0 if B is preferred to A. \n",
    "\n",
    "shp_dataset_formatted_train = []\n",
    "\n",
    "for example in shp_dataset_train:\n",
    "    prompt = example['history']\n",
    "    if example['labels'] == 1:\n",
    "        chosen_answer = example['human_ref_A']\n",
    "        rejected_answer = example['human_ref_B']\n",
    "    else:\n",
    "        chosen_answer = example['human_ref_B']\n",
    "        rejected_answer = example['human_ref_A']\n",
    "    \n",
    "    reformatted_example = {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen_answer,\n",
    "        \"rejected\": rejected_answer\n",
    "    }\n",
    "    \n",
    "    shp_dataset_formatted_train.append(reformatted_example)\n",
    "\n",
    "reformatted_json_shp_train = json.dumps(shp_dataset_formatted_train, indent=4)\n",
    "\n",
    "print(reformatted_json_shp_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_dataset_formatted_eval = []\n",
    "\n",
    "for example in shp_dataset_eval:\n",
    "    prompt = example['history']\n",
    "    if example['labels'] == 1:\n",
    "        chosen_answer = example['human_ref_A']\n",
    "        rejected_answer = example['human_ref_B']\n",
    "    else:\n",
    "        chosen_answer = example['human_ref_B']\n",
    "        rejected_answer = example['human_ref_A']\n",
    "    \n",
    "    reformatted_example = {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen_answer,\n",
    "        \"rejected\": rejected_answer\n",
    "    }\n",
    "    \n",
    "    shp_dataset_formatted_eval.append(reformatted_example)\n",
    "\n",
    "reformatted_json_shp_eval = json.dumps(shp_dataset_formatted_eval, indent=4)\n",
    "\n",
    "print(reformatted_json_shp_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_dataset_formatted_test = []\n",
    "\n",
    "for example in shp_dataset_test:\n",
    "    prompt = example['history']\n",
    "    if example['labels'] == 1:\n",
    "        chosen_answer = example['human_ref_A']\n",
    "        rejected_answer = example['human_ref_B']\n",
    "    else:\n",
    "        chosen_answer = example['human_ref_B']\n",
    "        rejected_answer = example['human_ref_A']\n",
    "    \n",
    "    reformatted_example = {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen_answer,\n",
    "        \"rejected\": rejected_answer\n",
    "    }\n",
    "    \n",
    "    shp_dataset_formatted_test.append(reformatted_example)\n",
    "\n",
    "reformatted_json_shp_test = json.dumps(shp_dataset_formatted_test, indent=4)\n",
    "\n",
    "print(reformatted_json_shp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(shp_dataset_formatted_train))\n",
    "print(len(shp_dataset_formatted_eval))\n",
    "print(len(shp_dataset_formatted_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the datasets\n",
    "with open(os.path.join(\"project-code-2024\", \"datasets\", \"shp_train.json\"), 'w') as f:\n",
    "    json.dump(shp_dataset_formatted_train, f, indent=4)\n",
    "\n",
    "with open(os.path.join(\"project-code-2024\", \"datasets\", \"shp_eval.json\"), 'w') as f:\n",
    "    json.dump(shp_dataset_formatted_eval, f, indent=4)\n",
    "\n",
    "with open(os.path.join(\"project-code-2024\", \"datasets\", \"shp_test.json\"), 'w') as f:\n",
    "    json.dump(shp_dataset_formatted_test, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
