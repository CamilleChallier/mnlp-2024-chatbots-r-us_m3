{"answer": "A", "question": "Question: Select the \\emph{weakest} algorithm.\n\nOptions:\nA. A5/4\nB. A5/2\nC. A5/3\nD. A5/1"}
{"answer": "B", "question": "Question: Tick the \\textit{incorrect} assertion. Consider a device that is running a software implementation of the PKCS\\#1v1.5 RSA cryptosystem.\n\nOptions:\nA. Analysing the power consumption of the device during decryption may be used to help recover the secret key.\nB. Inducing computational errors in the device during encryption may help recover the secret key.\nC. Issues related to message formatting may be used to help recover the secret key.\nD. Measuring the timing of the decryption computation may be used to help recover the secret key."}
{"answer": "D", "question": "Question: Let $n$ be an integer. Which of the following is \\emph{not} a group in the general case?\n\nOptions:\nA. $(\\mathbf{R},+)$\nB. $(\\mathbf{Q}\\setminus \\{0\\},\\times)$\nC. $(\\mathbf{Z}_n,+ \\pmod{n})$\nD. $(\\mathbf{Z}_n,\\times \\pmod{n})$"}
{"answer": "B", "question": "Question: Confidentiality means that:?\n\nOptions:\nA. the message can be read by anyone.\nB. information should not leak to any unexpected party.\nC. the message should make clear who the author is.\nD. the information must be protected against any malicious modification."}
{"answer": "A", "question": "Question: Nearest neighbor classifiers cannot be used for regression because they rely on majority voting, which is not suited for continuous labels.\n\nOptions:\nA. True\nB. False"}
{"answer": "C", "question": "Question: Select the statements that are true.A penalty will be applied to any incorrect answers selected.\n\nOptions:\nA. Information retrieval is the selection of documents relevant to a query from an unstructured collection of documents.\nB. Different IR systems can differ in the way they represent documents, represent queries, and define the relevance measure between documents and queries.\nC. The vector space model represents documents as vectors derived from the distribution of indexing terms in the document.\nD. The dimensionality of the vector space does not depend on the size of the indexing vocabulary.\nE. Use of filters during indexing results in less informative indexes."}
{"answer": "A", "question": "Question: Consider a binary classification problem with classifier $f(\\mathbf{x})$ given by $$ f(\\mathbf{x})= \\begin{cases}1, & g(\\mathbf{x}) \\geq 0 \\\\ -1, & g(\\mathbf{x})<0\\end{cases} $$ and $\\mathbf{x} \\in \\mathbb{R}^{6}$. Consider a specific pair $(\\mathbf{x}, y=1)$ and assume that $g(\\mathbf{x})=8$. In particular this means that this point is classified correctly by $f$. Assume further that we have computed the gradient of $g$ at $\\mathbf{x}$ to be $\\nabla_{\\mathbf{x}} g(\\mathbf{x})=(+1,-2,+3,-4,+5,-6)$. You are allowed to make one step in order to (hopefully) find an adversarial example. In the following four questions, assume $\\epsilon=1$. What is the value of $g(\\mathbf{x}+\\delta)$ for this $\\ell_{\\infty}$-optimal choice assuming that $g$ is (locally) linear?\n\nOptions:\nA. $-5$\nB. $-2$\nC. $-7$\nD. $+7$\nE. $4$\nF. $0$\nG. $+13$\nH. $2$\nI. $-4$\nJ. $-13$"}
{"answer": "A", "question": "Question: Which statement about \textit{black-box} adversarial attacks is true:?\n\nOptions:\nA. They require access to the gradients of the model being attacked. \nB. They are highly specific and cannot be transferred from a model which is similar to the one being attacked.\nC. They cannot be implemented via gradient-free (e.g., grid search or random search) optimization methods.\nD. They can be implemented using gradient approximation via a finite difference formula."}
{"answer": "A", "question": "Question: Consider a MAC defined by $\\mathsf{MAC}: \\{0,1\\}^* \\times \\{0,1\\}^k \\mapsto \\{0,1\\}^n$. The complexity of a generic key recovery attacks against $\\mathsf{MAC}$ is \\ldots?\n\nOptions:\nA. $2^{k/2}$\nB. $2^k$\nC. $2^{n/2}$\nD. $2^n$"}
{"answer": "A", "question": "Question: Consider the linear mask $\\alpha := \\mathsf{0xf0}$ and the input $X := \\mathsf{0xe2}$. We have $\\alpha \\cdot X = $ \\dots?\n\nOptions:\nA. $\\mathsf{0}$\nB. $\\mathsf{1}$\nC. $\\mathsf{0xe0}$\nD. $\\mathsf{0xf2}$"}
{"answer": "A", "question": "Question: (Nearest Neighbor) The training error of the 1-nearest neighbor classifier is zero.\n\nOptions:\nA. True\nB. False"}
{"answer": "A", "question": "Question: We are given a data set $S=\\left\\{\\left(\\boldsymbol{x}_{n}, y_{n}\\right)\\right\\}$ for a binary classification task where $\\boldsymbol{x}_{n}$ in $\\mathbb{R}^{D}$. We want to use a nearestneighbor classifier. In which of the following situations do we have a reasonable chance of success with this approach? [Ignore the issue of complexity.]?\n\nOptions:\nA. $n \\rightarrow \\infty, D$ is fixed\nB. $ n \\rightarrow \\infty, D \\ll \\ln (n)$\nC. $ n=D^2, D \\rightarrow \\infty$\nD. $ n$ is fixed, $D \\rightarrow \\infty$"}
{"answer": "C", "question": "Question: Let $H$ be a hash function. Collision resistance means that \\dots?\n\nOptions:\nA. given $y$, it is hard to find $x$ such that $H(x)=y$\nB. given $x$, it is hard to find $y$ such that $H(x)=y$\nC. it is hard to find $x_1$ and $x_2\\neq x_1$ such that $H(x_1)=H(x_2)$\nD. given $x_1$, it is hard to find $x_2\\neq x_1$ such that $H(x_1)=H(x_2)$"}
{"answer": "D", "question": "Question: Which of the following is correct regarding prediction models?\n\nOptions:\nA. A high bias is a sign of overfitting.\nB. A high variance is a sign of underfitting.\nC. In low data regime, complex models tend to perform better.\nD. Simple models have higher bias than complex models."}
{"answer": "C", "question": "Question: Let $E_{a,b}(\\mathrm{GF}(p))$ be non-singular elliptic curve with prime order, with $p$ a 256-bit prime and let $P,Q,R \\in E_{a,b}(\\mathrm{GF}(p)) \\backslash \\{\\mathcal{O}\\}$ such that $R=aP$ for an integer $a > 0$. Tick the \\textit{correct} assertion.\n\nOptions:\nA. It is hard to subtract $P$ from $Q$.\nB. The point at infinity $\\mathcal{O}$ does not have any inverse point.\nC. Given $P$ and $R$, it is hard to recover $a$.\nD. To compute the point $P+Q$, we just have to compute $(x_P+x_Q \\bmod{p}, y_P+y_Q \\bmod{p})$."}
{"answer": "A", "question": "Question: Consider the following sequence of random variables $S_1,\\ldots,S_n,\\ldots$ Assume that the limit $H^\\star(\\mathcal{S})=k$ exists and is finite. Suppose that there exists $\\hat{n}>0$ such that for all $i\\geq \\hat{n}$ one has that the marginal distributions of $S_{i+1}$ and $S_i$ satisfy $p_{S_{i+1}}=p_{S_i}$. Denote with $\\mathcal{Y}_{\\hat{n}}$ the alphabet of the source $S_{\\hat{n}}$. True or false: Can one use this information to infer that the following holds: $|\\mathcal{Y}_{\\hat{n}}| \\geq 2^k $?\n\nOptions:\nA. True\nB. False"}
{"answer": "C", "question": "Question: Fill the missing line of code: (one answer)\\\\\n \\hspace*{.5cm} \\#code missing\\\\\n \\hspace*{.5cm} np.mean(np.random.randn(1000))\\\\?\n\nOptions:\nA. import np\nB. import numpy\nC. import numpy as np\nD. import np.mean\\\\\n\t\timport np.random"}
{"answer": "A", "question": "Question: Consider the following joint distribution on $X$ and $Y$, where both random variables take on the values $\\{0,1\\}: p(X=$ $0, Y=0)=0.1, p(X=0, Y=1)=0.2, p(X=1, Y=0)=0.3, p(X=1, Y=1)=0.4$. You receive $X=1$. What is the largest probability of being correct you can achieve when predicting $Y$ in this case?\n\nOptions:\nA. $\\frac{1}{3}$\nB. $\\frac{3}{4}$\nC. $\\frac{1}{7}$\nD. $0$\nE. $1$\nF. $\\frac{2}{3}$\nG. $\\frac{6}{7}$\nH. $\\frac{4}{7}$\nI. $\\frac{3}{7}$\nJ. $\\frac{1}{4}$\nK. $\\frac{2}{4}$"}
{"answer": "A", "question": "Question: Let $(G,+)$ be a group of order $n$. If $g$ is a generator of this group, then it has order\\dots?\n\nOptions:\nA. $n/2$\nB. $\\sqrt{n}$\nC. $n-1$\nD. $n$"}
{"answer": "C", "question": "Question: Tick the \\textbf{non-commutative} operation.\n\nOptions:\nA. $+$ (addition) over $\\mathbb{Z}$\nB. $\\oplus$ (exclusive-or)\nC. $-$ (subtraction) over $\\mathbb{Z}$\nD. $\\times$ (multiplication) over $\\mathbb{Z}$"}
{"answer": "A", "question": "Question: Consider a binary classification problem with classifier $f(\\mathbf{x})$ given by $$ f(\\mathbf{x})= \\begin{cases}1, & g(\\mathbf{x}) \\geq 0 \\\\ -1, & g(\\mathbf{x})<0\\end{cases} $$ and $\\mathbf{x} \\in \\mathbb{R}^{6}$. Consider a specific pair $(\\mathbf{x}, y=1)$ and assume that $g(\\mathbf{x})=8$. In particular this means that this point is classified correctly by $f$. Assume further that we have computed the gradient of $g$ at $\\mathbf{x}$ to be $\\nabla_{\\mathbf{x}} g(\\mathbf{x})=(+1,-2,+3,-4,+5,-6)$. You are allowed to make one step in order to (hopefully) find an adversarial example. In the following four questions, assume $\\epsilon=1$. Which offset $\\delta$ with $\\|\\delta\\|_{\\infty} \\leq 1$ yields the smallest value for $g(\\mathbf{x}+\\delta)$, assuming that $g$ is (locally) linear?\n\nOptions:\nA. $(+1,-2,+3,-4,+5,-6)$\nB. $-(0,0,0,0,0,1)$\nC. $(0,0,0,0,0,1)$\nD. $(-1,-1,-1,-1,-1,-1)$\nE. $(+1,+1,+1,+1,+1,+1)$\nF. $(-1,+1,-1,+1,-1,+1)$\nG. $(+1,-1,+1,-1,+1,-1)$\nH. $(-1,+2,-3,+4,-5,+6)$"}
{"answer": "D", "question": "Question: Which of the following properties is part of the RDF Schema Language?\n\nOptions:\nA. Type\nB. Predicate\nC. Description\nD. Domain"}
{"answer": "C", "question": "Question: The output feedback (OFB) mode of operation \\dots?\n\nOptions:\nA. requires its nonce to be public and constant to be secure.\nB. requires its nonce IV to be constant but secret to be secure.\nC. requires its nonce to be new for every plaintext to be secure.\nD. doesn't require any nonce."}
{"answer": "B", "question": "Question: Select \\emph{incorrect} statement. The brute force technique against a cipher with key $256$ bits is?\n\nOptions:\nA. impossible even if we can compute without burning an energy.\nB. impossible since the number of possible keys is too high $2^{256} \\approx 10^{77}$.\nC. impossible in future even if we consider Moore's law.\nD. feasible using all clusters at EPFL."}
{"answer": "D", "question": "Question: Tick the \\emph{incorrect} statement. When $x\\rightarrow+\\infty$ \\ldots?\n\nOptions:\nA. $x^3 + 2x + 5 = \\mathcal{O}(x^3)$.\nB. $\\frac{1}{x^2} = \\mathcal{O}(\\frac{1}{x})$.\nC. $2^{\\frac{x}{\\log x}} = \\mathcal{O}(2^x)$.\nD. $n^x = \\mathcal{O}(x^n)$ for any constant $n>1$."}
{"answer": "B", "question": "Question: Which of the following is true regarding the random forest classification algorithm?\n\nOptions:\nA. It is not suitable for parallelization.\nB. It uses only a subset of features for learning in each weak learner.\nC. We compute a prediction by randomly selecting the decision of one weak learner.\nD. It produces a human interpretable model."}
{"answer": "B", "question": "Question: Let $n$ be an integer. Tick the \\emph{true} assertion about the Miller-Rabin Primality Test.\n\nOptions:\nA. If the algorithms outputs $prime$, then $n$ is definitely a prime.\nB. If the algorithms outputs $composite$, then $n$ is definitely \\emph{not} a prime.\nC. The test can be used to factorize $n$ if it is composite.\nD. The test always outputs $prime$ if $n$ is a Carmichael number."}
{"answer": "D", "question": "Question: Tick the \\textbf{false} statement regarding 3G.\n\nOptions:\nA. Confidentiality is preserved.\nB. Message integrity is preserved.\nC. Network is authenticated.\nD. It is secure against replay attacks."}
{"answer": "D", "question": "Question: When using linear regression, how do you help prevent numerical instabilities? (One or multiple answers)?\n\nOptions:\nA. reduce learning rate\nB. add a regularization term\nC. remove degenerate features\nD. add more features"}
{"answer": "B", "question": "Question: In RSA, we use CRT ...\n\nOptions:\nA. to speedup encryption.\nB. to speedup decryption.\nC. since it is necessary operation of the primitive.\nD. to prove security."}
{"answer": "B", "question": "Question: Let $X$ and $K$ be two independent random variables in a group $G$ with $n$ elements and where $K$ is uniformly distributed over $G$. Let $Y = X+K$. Then, for any $y\\in G$, $\\Pr[Y=y]=$\\dots?\n\nOptions:\nA. $1/n$.\nB. $\\Pr[X=y]$.\nC. $1/n^2$.\nD. $1/(n-1)$."}
{"answer": "A", "question": "Question: What is the algorithm to perform optimization with gradient descent? Actions between Start loop and End loop are performed multiple times. (One answer)?\n\nOptions:\nA. 1 Start loop, 2 Initialize weights, 3 Compute gradients, 4 Update weights, 5 End loop\nB. 1 Initialize weights,  2 Compute gradients, 3 Start loop, 4 Update weights, 5 End loop\nC. 1 Initialize weights,  2 Start loop, 3 Update weights, 4 End loop, 5 Compute gradients \nD. 1 Initialize weights, 2 Start loop, 3 Compute gradients, 4 Update weights, 5 End Loop"}
{"answer": "A", "question": "Question: Let $X$, $Y$, and $K$ be respectively the plaintext, ciphertext, and key distributions. $H$ denotes the Shannon entropy. The consequence of perfect secrecy is \\dots?\n\nOptions:\nA. $H(K) \\geq H(X)$\nB. $H(K) \\leq H(X)$\nC. $H(K,X) \\leq H(X)$\nD. $H(Y) \\leq H(X)$"}
{"answer": "B", "question": "Question: Take the recurrence relation $$a_n = -3a_{n-1} + 4a_{n-2}$$ with initial conditions $$a_0 = 1$$, $$a_1=3$$ and transform it in the form $$a_n = \u0007lpha_1r_1^n + \u0007lpha_2r_2^n$$. Which statement is true?\n\nOptions:\nA. $$\u0007lpha_1 = \frac{4}{5}$$ and $$\u0007lpha_2 = \frac{1}{5}$$\nB. $$\u0007lpha_1 = -4$$ and $$\u0007lpha_2=1$$\nC. $$\u0007lpha_1 = \frac{7}{5}$$ and $$\u0007lpha_2 = \frac{-2}{5}$$\nD. $$\u0007lpha_1 = \frac{13}{5}$$ and $$\u0007lpha_2 = \frac{-7}{5}$$"}
{"answer": "B", "question": "Question: Tick the \\emph{true} assertion among the followings:?\n\nOptions:\nA. Visual cryptography is perfectly secure (at an unreasonable cost).\nB. The Vernam cipher was invented by Kerckoff.\nC. Just like coding theory, cryptography usually faces random noise.\nD. Enigma has never been broken."}
{"answer": "B", "question": "Question: Following are token counts that appear in 3 documents (D1, D2, and D3):\nD1 \u2013\u00a0tablet: 7;\u00a0memory: 5;\u00a0app: 8;\u00a0sluggish: 7\nD2 \u2013\u00a0memory: 5;\u00a0app: 3\nD3 \u2013\u00a0tablet: 3;\u00a0sluggish: 3\nBased on the cosine similarity, which 2 documents are the most similar?\n?\n\nOptions:\nA. D1 and D2\nB. D1 and D3\nC. D2 and D3"}
{"answer": "D", "question": "Question: Let $f$ be any hash function with output domain size $N$.\n\nOptions:\nA. One can find a collision in $f$ in $\\mathcal{O}(\\sqrt{N})$ using almost no memory.\nB. One can find a preimage in $f$ in $\\mathcal{O}(\\sqrt{N})$ using $\\sqrt{N}$ memory.\nC. One can find a second preimage in $f$ in $\\mathcal{O}(\\sqrt{N})$ using $\\sqrt{N}$ memory.\nD. The best collision attack against $f$ runs in time $\\mathcal{O}(N)$."}
{"answer": "B", "question": "Question: The training loss of logistic regression is always zero.\n\nOptions:\nA. TRUE\nB. FALSE"}
{"answer": "C", "question": "Question: Which of the following is/are true about fuzzing libraries?\n\nOptions:\nA. Fuzzing libraries is harder than standalone executables as no\n               single ``binary'' is available for a complex API.\nB. To fuzz effectively, every argument of every function must be\n                  fuzzed independently.\nC. Every function of a library is part of the API that needs to be fuzzed.\nD. FuzzGen's A\\textsuperscript{2}DG contains the control but not\n                  the data dependencies of the API calls."}
{"answer": "D", "question": "Question: Given that $100000000003$ is prime, what is the cardinality of $\\mathbf{Z}_{200000000006}^*$?\n\nOptions:\nA. $2$\nB. $100000000002$\nC. $100000000003$\nD. $200000000006$"}
{"answer": "A", "question": "Question: Let S(x) be the statement \u201cx has been in a lake\u201d and L(x) be the statement \u201cx lives in Lausanne\u201d and the domain of x consists of all the humans in the world.\n\nThe sentence : \u201cthere exists exactly one human that lives in Lausanne and that has never been in a lake\u201d corresponds to the statement (multiple choices possible):?\n\nOptions:\nA. \\( \\exists! x (S(x) \\wedge L(x)) \\)\nB. \\( \\exists x \\Bigr[( S(x) \\wedge \neg L(x)) \\wedge \forall y \\left[  \neg( S(y) \\wedge \neg L(y)) \\wedge (x=y) \right] \\Bigr] \\)\nC. \\( \\exists x \\Bigr[ (\neg S(x) \\wedge L(x)) \\wedge \forall y \\left[ \neg(\neg S(y) \\wedge L(y)) \u000bee (x=y) \right] \\Bigr] \\)\nD. \\( \\exists! x (\neg S(x) \\wedge L(x)) \\)"}
{"answer": "D", "question": "Question: MD5 is?\n\nOptions:\nA. a secure block cipher\nB. a broken block cipher\nC. a secure hash function\nD. a broken hash function"}
{"answer": "C", "question": "Question: Given a document collection, if we change the ordering of the words in the documents, which of the following will not change?\n\nOptions:\nA. Singular values in Latent Semantic Indexing (LSI)\nB. The entities extracted using a Hidden Markov Model (HMM)\nC. The embedding vectors produced by Word2vec\nD. All the previous will change"}
{"answer": "A", "question": "Question: Given the 2-itemsets {1, 2}, {1, 3}, {1, 5}, {2, 3}, {2, 5}, when generating the 3-itemset we will:?\n\nOptions:\nA. Have 4 3-itemsets after the join and 4 3-itemsets after the prune\nB. Have 4 3-itemsets after the join and 2 3-itemsets after the prune\nC. Have 3 3-itemsets after the join and 3 3-itemsets after the prune\nD. Have 2 3-itemsets after the join and 2 3-itemsets after the prune"}
{"answer": "C", "question": "Question: Which operation does the following function implement? extension [U](l: List[U]) def secret[T](t: T)(f: (T, U) => T): T = \\t var res = t \\t l.foreach(u => res = f(res, u)) \\t res?\n\nOptions:\nA. reduceLeft\nB. reduceRight\nC. foldLeft\nD. foldRight"}
{"answer": "D", "question": "Question: How many generators are there in $\\mathbb{Z}_n$?\n\nOptions:\nA. $1$\nB. $n-1$\nC. $n$\nD. $\\varphi (n)$"}
{"answer": "D", "question": "Question: In a MAC forgery, the adversary tries to\\dots?\n\nOptions:\nA. recover the message $m$ given the tag \\textsf{MAC}_K(m).\nB. decrypt a given message.\nC. forge the secret key.\nD. compute the MAC of a message whose MAC was never computed before."}
{"answer": "A", "question": "Question: Recall can be defined as:?\n\nOptions:\nA. P(relevant documents | retrieved documents)\nB. P(retrieved documents relevant documents)\nC. P(retrieved documents number of documents)\nD. P(relevant documents number of documents)"}
{"answer": "B", "question": "Question: Birthday attacks \\dots?\n\nOptions:\nA. are used to break Google Calendars.\nB. can be used to find collisions in hash functions.\nC. are equivalent to exhaustive search.\nD. imply that a majority of people is born in Spring."}
{"answer": "D", "question": "Question: \nYour aim is to evaluate a movie review analysis system, the purpose of which is to determine whether a review is globally positive or negative.\nFor each movie review, such a system outputs one of the following classes: positive and negative.\nTo perform your evaluation, you collect a large set of reviews and have it annotated by two human annotators. This corpus contains 95% of negative reviews (this 95% ratio is for this first question only and may change in the next\n            questions).\n\nWhat metrics do you think are appropriate to evaluate the system on this corpus?\n\nYou will get a penalty for wrong ticks.\n?\n\nOptions:\nA. Cohen's kappa\nB. accuracy\nC. precision\nD. recall\nE. standard deviation\nF. F1-score"}
{"answer": "C", "question": "Question: In JOS and x86, please select all valid options for a system call.\n\nOptions:\nA. A system call is for handling interrupts like dividing zero error and page fault.\nB. In user mode, before and after a system call instruction(such as int 0x30), the stack pointer(esp in x86) stays the same.\nC. During the execution of a system call, when transfering from user mode to kernel mode, the stack pointer(esp in x86) stays the same."}
{"answer": "A", "question": "Question: When constructing a word embedding, what is true regarding negative samples?\n\nOptions:\nA. They are words that do not appear as context words\nB. They are selected among words which are not stop words\nC. Their frequency is decreased down to its logarithm\nD. They are oversampled if less frequent"}
{"answer": "D", "question": "Question: Let $\\mathcal{C}$ be a binary $(n,k)$ linear code with minimum distance $d_{\\min} = 4$. Let $\\mathcal{C}'$ be the code obtained by adding a parity-check bit $x_{n+1}=x_1 \\oplus x_2 \\oplus \\cdots \\oplus x_n$ at the end of each codeword of $\\mathcal{C}$. Let $d_{\\min}'$ be the minimum distance of $\\mathcal{C}'$. Which of the following is true?\n\nOptions:\nA. $d_{\\min}' = 4$\nB. $d_{\\min}' = 5$\nC. $d_{\\min}' = 6$\nD. $d_{\\min}'$ can take different values depending on the code $\\mathcal{C}$."}
{"answer": "A", "question": "Question: One of the following ciphers is a \\emph{block} cipher. Which one?\n\nOptions:\nA. AES\nB. RC4\nC. A5/1\nD. MD5"}
{"answer": "A", "question": "Question: Finding collisions on a set of N elements ...\n\nOptions:\nA. requires the storage of size $ \\Omega(N).$\nB. requires time $ O({N}^{\\frac{1}{3}}).$\nC. can be done with the storage of size $O(1).$\nD. is doable for $N=2^{256}$."}
{"answer": "A", "question": "Question: Let $X_1,X_2,\\dots$ be i.i.d. binary random variables with $p_{X_i}(1) =\frac{1}{4}$ for every $i\\geq 1$. Let $Y_1$ be a uniform binary random variable, and let $Y_i = Y_{i-1} \\oplus X_{i-1}$ for every $i\\geq 2$, where $\\oplus$ denotes the modulo-2 sum. For any given $n\\geq 1$, what is the value of $H(Y_1,Y_2,\\dots,Y_n)$? [Hint: what is the value of $H(Y_i|Y_1,\\dots,Y_{i-1})$?]?\n\nOptions:\nA. $\\left(2-\frac{3}{4}\\log 3\right) n + \frac{3}{4}\\log 3 - 1$.\nB. $n$.\nC. $\\left(2-\frac{3}{4}\\log 3\right) n + 1$.\nD. $\\left(3 - \frac{3}{4}\\log 3\right) n +\frac{3}{4}\\log 3 -2$."}
{"answer": "A", "question": "Question: Tick the assertion related to an open problem.\n\nOptions:\nA. $NP\\subseteq IP$.\nB. $P\\subseteq IP$.\nC. $PSPACE=IP$.\nD. $NP = \\text{co-}NP$."}
{"answer": "A", "question": "Question: We consider a month of 30 days. I have \\(n\\) chocolates and each day, I can either: not eat chocolate or eat exactly one chocolate. All chocolates needs to be eaten by the end of the month. What is the smallest number of chocolates needed to guarantee that I will eat chocolate 5 days in a row during the month?\n\nOptions:\nA. 27\nB. 25\nC. 24\nD. 26"}
{"answer": "D", "question": "Question: The CRT states?\n\nOptions:\nA. $\\mathbb{Z}_{mn} \\equiv \\mathbb{Z}_{m} \\cup \\mathbb{Z}_{n}$\nB. $\\mathbb{Z}_{mn} \\equiv \\mathbb{Z}_{m} \\setminus \\mathbb{Z}_{n}$\nC. $\\mathbb{Z}_{mn} \\equiv \\mathbb{Z}_{m} \\cap \\mathbb{Z}_{n}$\nD. $\\mathbb{Z}_{mn} \\equiv \\mathbb{Z}_{m} \\times \\mathbb{Z}_{n}$"}
{"answer": "B", "question": "Question: Which of the following is correct regarding schemas and ontologies?\n\nOptions:\nA.  An ontology is created from constructing mappings between schemas\nB. Ontologies can be used for reasoning about different schemas\nC. Ontologies always require a schema\nD. Semi-structured data cannot have a schema"}
{"answer": "B", "question": "Question: Consider the group $(\\mathbb{Z} / 23 \\mathbb{Z}^*, \\cdot)$. Find how many elements of the group are generators of the group. (Hint: $5$ is a generator of the group.)?\n\nOptions:\nA. $10$\nB. $22$\nC. $11$\nD. $2$"}
{"answer": "A", "question": "Question: How many generators do we have in a group of order $13$?\n\nOptions:\nA. 13.\nB. 12.\nC. 6.\nD. 2."}
{"answer": "C", "question": "Question: Tick the \\emph{false} assertion.\n\nOptions:\nA. RSA-PSS is a signature scheme.\nB. RSA-OAEP is an encryption scheme.\nC. The RSA based encryption scheme of the standard PKCS \\#1 v1.5 is vulnerable to a side channel attack.\nD. The RSA based scheme ISO/IEC 9796 is an encryption scheme."}
{"answer": "C", "question": "Question: Recall that the hard-margin SVM problem corresponds to:\n\t$$ \\underset{\\substack{\\ww \\in \\R^d, \\ \forall i:\\ y_i \\ww^\top \\xx_i \\geq 1}}{\\min} \\Vert \\ww \\Vert_2.$$\n\tNow consider the $2$-dimensional classification dataset corresponding to the $3$ following datapoints: $\\xx_1 = (-1, 2)$, $\\xx_2 = (1, 2)$, $\\xx_3 = (0, -2)$ and  $y_1 = y_2 = 1$, $y_3 = -1$.\n\tWhich of the following statements is \textbf{true}:\n        ?\n\nOptions:\nA. Our dataset is not linearly separable and hence it does not make sense to consider the hard-margin problem.\nB. There exists a unique $\\ww^\\star$ which linearly separates our dataset.\nC. The unique vector which solves the hard-margin problem for our dataset is $\\ww^\\star = (0, 1)$.\nD. None of the other statements are true."}
{"answer": "C", "question": "Question: Graph coloring is \\ldots?\n\nOptions:\nA. \\ldots $NP$-hard with 1 color.\nB. \\ldots not interesting for cryptographers.\nC. \\ldots an $NP$-complete problem when limited to 3 colors.\nD. \\ldots always possible with 2 colors."}
{"answer": "A", "question": "Question: Which of these primitives can be surely considered insecure today?\n\nOptions:\nA. Symmetric key encryption with an $82$ bit key.\nB. RSA encryption scheme with a $1613$ bit modulus.\nC. A signature scheme based on a random elliptic curve over a finite field $\\mathrm{GF}(q)$ of cardinality $q > 2^{200}$.\nD. Diffie-Hellman key exchange over a prime-order subgroup of $\\mathbb{Z}_p^*$ that has order $\\approx 2^{200}$ with a prime $p$ of $512$ bits."}
{"answer": "A", "question": "Question: Which one of the following notions means that ``the information should make clear who the author of it is''?\n\nOptions:\nA. authentication\nB. steganograhy\nC. privacy\nD. confidentiality"}
{"answer": "B", "question": "Question: What is TRUE regarding the Multi-head Self-attention mechanism?\n\nOptions:\nA. Its computation cannot be parallelized compared to LSTMs and other sequential models.\nB. It gives the Transformer the ability to learn different aspects of the meanings of each word.\nC. LSTMs have larger memory than models with self-attention.\nD. Its complexity is linear to the input size."}
{"answer": "B", "question": "Question: If you write \"hello\" to a file in a JOS file system. Right after the write operation, the computer crashes. Is the content \"hello\" persisted (or written) on the disk?\n\nOptions:\nA. Yes\nB. No"}
{"answer": "A", "question": "Question: In Machine Learning, we want to learn the \\textbf{parameters W} for the mapping function f: $y=f(x,W) +\\epsilon$ where x is the input, y the output, and $\\epsilon$ the error term.\\\\\n(One or multiple answers)?\n\nOptions:\nA. When f: $R \\rightarrow \\{1,..N\\}$, it is a classification task\nB. When f: $R^M \\rightarrow \\{1,..N\\}$, it is a classification task\nC. When f: $R^M \\rightarrow R$, it is a classification task \nD. When f: $R^M \\rightarrow R$, it is a regression task"}
{"answer": "D", "question": "Question: What is the order of 11 in $\\mathbb{Z}_{37}$?\n\nOptions:\nA. 1\nB. 27\nC. 36\nD. 37"}
{"answer": "A", "question": "Question: The differential probability of a function $f:\\{0,1\\}^p\\rightarrow \\{0,1\\}^q$ is, given $a\\in\\{0,1\\}^p$ and $b\\in\\{0,1\\}^q$, defined by \\dots?\n\nOptions:\nA. $\\mathrm{DP}^f(a,b)=\\Pr_{X\\in _U \\{0,1\\}^p} [f(X\\oplus a)=f(X\\oplus b)] $.\nB. $\\mathsf{DP}^f(a,b)=\\Pr_{X\\in _U \\{0,1\\}^p} [f(X)\\oplus a=f(X)\\oplus b] $.\nC. $\\mathsf{DP}^f(a,b)=\\Pr_{X\\in _U \\{0,1\\}^p} [f(X\\oplus b)=f(X)\\oplus a] $.\nD. $\\mathsf{DP}^f(a,b)=\\Pr_{X\\in _U \\{0,1\\}^p} [f(X\\oplus a)=f(X)\\oplus b] $."}
{"answer": "A", "question": "Question: In terms of the \\textbf{bias-variance} decomposition, a 1-nearest neighbor classifier has \\rule{2cm}{0.15mm} than a 3-nearest neighbor classifier.\n\nOptions:\nA. higher variance\nB. lower variance\nC. higher bias\nD. lower bias"}
{"answer": "D", "question": "Question: In classification, which of the following is true regarding class imbalance?\n\nOptions:\nA. Classes should have the same distribution in the validation set and in the full dataset.\nB. Oversampling the larger class can reduce the impact of the skewed distribution.\nC. Oversampling rare classes in the testing set can reduce the impact of skewed distribution.\nD. The leave-one-out methodology produces the same class distribution in the training and the testing set."}
{"answer": "B", "question": "Question: Which of the following provides forward secrecy.\n\nOptions:\nA. Transferring keys in plain.\nB. Ephemeral Diffie-Hellman.\nC. Semi-static Diffie-Hellman.\nD. Static Diffie-Hellman."}
{"answer": "A", "question": "Question: Dans un syst\u00e8me ind\u00e9formable, comment est d\u00e9finie la tension induite ? (plusieurs r\u00e9ponses possibles)?\n\nOptions:\nA. l'oppos\u00e9 (-) de l'int\u00e9grale du champ d'induction magn\u00e9tique (densit\u00e9 de flux) sur une surface\nB. l'oppos\u00e9 (-) de l'int\u00e9grale du champ \u00e9lectrique sur un contour ferm\u00e9\nC. la d\u00e9riv\u00e9e par rapport au temps du champ d'induction magn\u00e9tique (densit\u00e9 de flux)\nD. la d\u00e9riv\u00e9e par rapport au temps du flux totalis\u00e9"}
{"answer": "C", "question": "Question: Which cryptographic primitive(s) is (are) used in S/Key - OTP ?\n\nOptions:\nA. Only encryption and a hash function\nB. Only encryption and a MAC algorithm\nC. Only a hash function\nD. Only a MAC"}
{"answer": "B", "question": "Question: Tick the \\emph{correct} assertion concerning WPA2?\n\nOptions:\nA. WPA2 uses RC4.\nB. WPA2 uses AES.\nC. WPA2 uses 64-bit keys.\nD. WPA2 is badly broken."}
{"answer": "B", "question": "Question: Tick the \\emph{correct} assertion. Linear cryptanalysis \\ldots?\n\nOptions:\nA. was invented long before the Caesar cipher.\nB. is a chosen plaintext key recovery attack.\nC. requires $\\frac{1}{DP}$ pairs of plaintext-ciphertext.\nD. breaks DES with $2^{43}$ known plaintexts."}
